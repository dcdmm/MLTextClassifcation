{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML, clear_output\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, minmax_scale\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_PATH = '../input/optiver-realized-volatility-prediction'\n",
    "DATA_EXTRA_PATH = '../input/optiver'\n",
    "TRAIN_PATH = DATA_PATH + '/train.csv'\n",
    "TEST_PATH = DATA_PATH + '/test.csv'\n",
    "TRAIN_FOLD_PATH = DATA_EXTRA_PATH + '/train_fold.csv'\n",
    "\n",
    "\n",
    "# Function to process features as input to FFNN model\n",
    "def process_nn_data(train_nn, test_nn):\n",
    "\n",
    "    train_nn.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    test_nn.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "\n",
    "    train_nn = train_nn[colNames]\n",
    "    test_nn = test_nn[colNames]\n",
    "\n",
    "    for col in colNames:\n",
    "        qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "        train_nn[col] = qt.fit_transform(train_nn[[col]])\n",
    "        test_nn[col] = qt.transform(test_nn[[col]])\n",
    "\n",
    "    train_nn[colNames] = train_nn[colNames].fillna(train_nn[colNames].mean())\n",
    "    test_nn[colNames] = test_nn[colNames].fillna(train_nn[colNames].mean())\n",
    "\n",
    "    train_nn[['stock_id','time_id','target']] = train_master[['stock_id','time_id','target']]\n",
    "    test_nn[['stock_id','time_id']] = test_master[['stock_id','time_id']]\n",
    "\n",
    "    return train_nn, test_nn\n",
    "\n",
    "# Function to process features as input to TabNet model\n",
    "def process_tabnet_data(train, test):\n",
    "\n",
    "    train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "\n",
    "    for col in train.columns.to_list()[5:]:\n",
    "        train[col] = train[col].fillna(train[col].mean())\n",
    "        train = train.fillna(0)\n",
    "\n",
    "    for col in test.columns.to_list()[3:]:\n",
    "        test[col] = test[col].fillna(test[col].mean())\n",
    "        test = test.fillna(0)\n",
    "\n",
    "    X = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "    y = train['target']\n",
    "\n",
    "    X_test=test.drop(['time_id','row_id'], axis=1)\n",
    "\n",
    "    nunique = X.nunique()\n",
    "    types = X.dtypes\n",
    "\n",
    "    categorical_columns = []\n",
    "    categorical_dims =  {}\n",
    "\n",
    "    for col in X.columns:\n",
    "        if  col == 'stock_id':\n",
    "            l_enc = LabelEncoder()\n",
    "            X[col] = l_enc.fit_transform(X[col].values)\n",
    "            X_test[col] = l_enc.transform(X_test[col].values)\n",
    "            categorical_columns.append(col)\n",
    "            categorical_dims[col] = len(l_enc.classes_)\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            X[col] = scaler.fit_transform(X[col].values.reshape(-1, 1))\n",
    "            X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))\n",
    "\n",
    "    cat_idxs = [ i for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]\n",
    "\n",
    "    cat_dims = [ categorical_dims[f] for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]\n",
    "\n",
    "    return X, y, X_test, cat_idxs, cat_dims\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-27T09:35:42.076418Z",
     "iopub.execute_input": "2021-10-27T09:35:42.076697Z",
     "iopub.status.idle": "2021-10-27T09:35:42.083843Z",
     "shell.execute_reply.started": "2021-10-27T09:35:42.076662Z",
     "shell.execute_reply": "2021-10-27T09:35:42.082587Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# FFNN base model\n",
    "def base_model(input_shape, hidden_units, stock_embedding_size):\n",
    "\n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(input_shape,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size,\n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "\n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "\n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to train FFNN\n",
    "def train_and_evaluate_nn(train_nn, test_nn):\n",
    "\n",
    "    oof_predictions_nn = np.zeros(train_nn.shape[0])\n",
    "    test_predictions_nn = np.zeros(test_nn.shape[0])\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "    plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n",
    "    mode='min')\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    num_data = scaler.fit_transform(train_nn[colNames].values)\n",
    "\n",
    "    for fold in range(5):\n",
    "        print('CV {}/{}'.format(fold+1, 5))\n",
    "\n",
    "        trn_ind = train_nn[kfolds!=fold].index\n",
    "        val_ind = train_nn[kfolds==fold].index\n",
    "\n",
    "        y_train = train_nn.loc[trn_ind, 'target']\n",
    "        y_test = train_nn.loc[val_ind, 'target']\n",
    "\n",
    "        num_data = scaler.transform( train_nn.loc[trn_ind, colNames].values)\n",
    "        num_data_test = scaler.transform( train_nn.loc[val_ind, colNames].values)\n",
    "\n",
    "        cat_data = train_nn['stock_id'][trn_ind]\n",
    "        cat_data_test = train_nn['stock_id'][val_ind]\n",
    "\n",
    "        # 3 NN models per fold\n",
    "        for ff in range(3):\n",
    "\n",
    "            model = base_model(input_shape, hidden_units, stock_embedding_size)\n",
    "\n",
    "            model.compile(\n",
    "              keras.optimizers.Adam(learning_rate=0.006),\n",
    "              loss=root_mean_squared_per_error\n",
    "            )\n",
    "\n",
    "            model.fit([cat_data, num_data],\n",
    "                    y_train,\n",
    "                    batch_size=2048,\n",
    "                    epochs=1000,\n",
    "                    validation_data=([cat_data_test, num_data_test], y_test),\n",
    "                    callbacks=[es, plateau],\n",
    "                    validation_batch_size=len(y_test),\n",
    "                    shuffle=True,\n",
    "                  verbose = 0)\n",
    "\n",
    "            preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "            oof_predictions_nn[val_ind] += preds\n",
    "\n",
    "            score = round(rmspe(y_true=y_test, y_pred=preds),5)\n",
    "            print('Fold {}/{}: {}'.format(fold, ff, score))\n",
    "\n",
    "            test_predictions_nn += model.predict([test_nn['stock_id'], scaler.transform(test_nn[colNames].values)]).reshape(1,-1)[0].clip(0,1e10)\n",
    "            gc.collect()\n",
    "\n",
    "        del num_data, num_data_test, cat_data, cat_data_test, y_train, y_test\n",
    "        gc.collect()\n",
    "\n",
    "    test_predictions_nn = test_predictions_nn / 15.0\n",
    "    oof_predictions_nn = oof_predictions_nn/3.0\n",
    "    rmspe_score = rmspe(train_nn['target'], oof_predictions_nn)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "\n",
    "    return test_predictions_nn, oof_predictions_nn\n",
    "\n",
    "# Function to train TabNet model\n",
    "def train_tabnet(X, y, X_test, tabnet_params):\n",
    "\n",
    "    oof_predictions = np.zeros((X.shape[0], 1))\n",
    "    test_predictions = np.zeros(X_test.shape[0])\n",
    "\n",
    "    for fold in range(5):\n",
    "\n",
    "        print(f'Training fold {fold + 1}')\n",
    "\n",
    "        trn_ind = kfolds!=fold\n",
    "        val_ind = kfolds==fold\n",
    "\n",
    "\n",
    "        clf =  TabNetRegressor(**tabnet_params)\n",
    "        clf.fit(\n",
    "          X[trn_ind].values, y[trn_ind].values.reshape(-1,1),\n",
    "          eval_set=[(X[val_ind].values, y[val_ind].values.reshape(-1,1))],\n",
    "          max_epochs = 200,\n",
    "          patience = 50,\n",
    "          batch_size = 1024*10,\n",
    "          virtual_batch_size = 128*10,\n",
    "          num_workers = 4,\n",
    "          drop_last = False,\n",
    "          eval_metric=[RMSPE],\n",
    "          loss_fn=RMSPELoss,\n",
    "          )\n",
    "\n",
    "        saving_path_name = BASE_PATH + '/models/tabnet_latest_2/model_fold_{}'.format(fold)\n",
    "        saved_filepath = clf.save_model(saving_path_name)\n",
    "\n",
    "        oof_predictions[val_ind] = clf.predict(X[val_ind].values)\n",
    "        test_predictions+=clf.predict(X_test.values).flatten()/5\n",
    "\n",
    "    print(f'OOF score across folds: {rmspe(y, oof_predictions.flatten())}')\n",
    "\n",
    "    return test_predictions, oof_predictions\n",
    "\n",
    "# Function to get TabNet predictions from pre-trained models\n",
    "def get_tabnet_preds(X_test, tabnet_params):\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    shutil.make_archive('model_fold_0', 'zip', '../input/optiver-tabnet/model_fold_0')\n",
    "    shutil.make_archive('model_fold_1', 'zip', '../input/optiver-tabnet/model_fold_1')\n",
    "    shutil.make_archive('model_fold_2', 'zip', '../input/optiver-tabnet/model_fold_2')\n",
    "    shutil.make_archive('model_fold_3', 'zip', '../input/optiver-tabnet/model_fold_3')\n",
    "    shutil.make_archive('model_fold_4', 'zip', '../input/optiver-tabnet/model_fold_4')\n",
    "\n",
    "    modelpath = ['./model_fold_0.zip','./model_fold_1.zip',\n",
    "                './model_fold_2.zip','./model_fold_3.zip','./model_fold_4.zip']\n",
    "\n",
    "    clf = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "    for path in modelpath:\n",
    "\n",
    "        clf.load_model(path)\n",
    "        preds.append(clf.predict(X_test.values).squeeze(-1))\n",
    "\n",
    "    preds = np.clip(np.mean(preds,axis=0), 0, 1e10)\n",
    "\n",
    "    return preds\n",
    "\n",
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-27T09:35:42.216535Z",
     "iopub.execute_input": "2021-10-27T09:35:42.216786Z",
     "iopub.status.idle": "2021-10-27T09:35:42.276442Z",
     "shell.execute_reply.started": "2021-10-27T09:35:42.216762Z",
     "shell.execute_reply": "2021-10-27T09:35:42.275848Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error in LGBM\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "# Function to calculate the root mean squared percentage error in TF\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "\n",
    "# Class to be able to use custom RMSPE loss in TabNet\n",
    "class RMSPE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"rmspe\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "\n",
    "        return np.sqrt(np.mean(np.square((y_true - y_score) / y_true)))\n",
    "\n",
    " # Function to calculate the root mean squared percentage error in Torch\n",
    "def RMSPELoss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 )).clone()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-27T09:35:42.277794Z",
     "iopub.execute_input": "2021-10-27T09:35:42.278180Z",
     "iopub.status.idle": "2021-10-27T09:35:42.286407Z",
     "shell.execute_reply.started": "2021-10-27T09:35:42.278147Z",
     "shell.execute_reply": "2021-10-27T09:35:42.285641Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate distance matrix from reconstructed stock prices\n",
    "d_df = calc_distance_matrix()\n",
    "\n",
    "# Kfolds are in csv file\n",
    "train, test = read_train_test()\n",
    "kfolds = pd.read_csv(TRAIN_FOLD_PATH)['kfold']\n",
    "\n",
    "train, test = calc_features_from_raw_data(train, test)\n",
    "\n",
    "train = get_time_agg(train)\n",
    "test = get_time_agg(test)\n",
    "\n",
    "train = calc_taus(train)\n",
    "test = calc_taus(test)\n",
    "\n",
    "train, test = calc_tick_features(train, test)\n",
    "train, test = calc_cluster_features(train, test)\n",
    "\n",
    "colNames = [col for col in list(train.columns)\n",
    "            if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n",
    "\n",
    "train_master = train.copy()\n",
    "test_master = test.copy()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-27T09:35:42.287772Z",
     "iopub.execute_input": "2021-10-27T09:35:42.288345Z",
     "iopub.status.idle": "2021-10-27T10:00:13.625718Z",
     "shell.execute_reply.started": "2021-10-27T09:35:42.288303Z",
     "shell.execute_reply": "2021-10-27T10:00:13.624406Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FFNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train = train_master.copy()\n",
    "test = test_master.copy()\n",
    "\n",
    "train, test = process_nn_data(train, test)\n",
    "gc.collect()\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "cat_data = train['stock_id']\n",
    "input_shape = len(colNames)\n",
    "\n",
    "predictions_nn, oof_predictions_nn = train_and_evaluate_nn(train, test)\n",
    "\n",
    "del train, test\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-27T10:19:28.723692Z",
     "iopub.execute_input": "2021-10-27T10:19:28.723983Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TabNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "random_seed(42)\n",
    "\n",
    "train = train_master.copy()\n",
    "test = test_master.copy()\n",
    "\n",
    "X, y, X_test, cat_idxs, cat_dims = process_tabnet_data(train, test)\n",
    "\n",
    "tabnet_params = dict(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=8,\n",
    "    n_d = 16,\n",
    "    n_a = 16,\n",
    "    n_steps = 2,\n",
    "    gamma = 1.3,\n",
    "    n_independent = 2,\n",
    "    n_shared = 2,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = Adam,\n",
    "    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(T_0=200, T_mult=1, eta_min=1e-4, last_epoch=-1, verbose=False),\n",
    "    scheduler_fn = CosineAnnealingWarmRestarts,\n",
    "    seed = 23,\n",
    "    verbose = 10)\n",
    "\n",
    "tabnet_predictions = get_tabnet_preds(X_test, tabnet_params)\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train, test = read_train_test()\n",
    "\n",
    "test['target'] = (tabnet_predictions + predictions_nn+predictions_lgb)/3.0\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)\n",
    "test[['row_id', 'target']].head()\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}