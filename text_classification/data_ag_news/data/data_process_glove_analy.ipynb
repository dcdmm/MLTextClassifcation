{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "        class                                               text\n0           3  Wall St. Bears Claw Back Into the Black (Reute...\n1           3  Carlyle Looks Toward Commercial Aerospace (Reu...\n2           3  Oil and Economy Cloud Stocks' Outlook (Reuters...\n3           3  Iraq Halts Oil Exports from Main Southern Pipe...\n4           3  Oil prices soar to all-time record, posing new...\n...       ...                                                ...\n119995      1  Pakistan's Musharraf Says Won't Quit as Army C...\n119996      2  Renteria signing a top-shelf deal Red Sox gene...\n119997      2  Saban not going to Dolphins yet The Miami Dolp...\n119998      2  Today's NFL games PITTSBURGH at NY GIANTS Time...\n119999      2  Nets get Carter from Raptors INDIANAPOLIS -- A...\n\n[120000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119995</th>\n      <td>1</td>\n      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n    </tr>\n    <tr>\n      <th>119996</th>\n      <td>2</td>\n      <td>Renteria signing a top-shelf deal Red Sox gene...</td>\n    </tr>\n    <tr>\n      <th>119997</th>\n      <td>2</td>\n      <td>Saban not going to Dolphins yet The Miami Dolp...</td>\n    </tr>\n    <tr>\n      <th>119998</th>\n      <td>2</td>\n      <td>Today's NFL games PITTSBURGH at NY GIANTS Time...</td>\n    </tr>\n    <tr>\n      <th>119999</th>\n      <td>2</td>\n      <td>Nets get Carter from Raptors INDIANAPOLIS -- A...</td>\n    </tr>\n  </tbody>\n</table>\n<p>120000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../datasets/train.csv')\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "      class                                               text\n0         3  Fears for T N pension after talks Unions repre...\n1         4  The Race is On: Second Private Team Sets Launc...\n2         4  Ky. Company Wins Grant to Study Peptides (AP) ...\n3         4  Prediction Unit Helps Forecast Wildfires (AP) ...\n4         4  Calif. Aims to Limit Farm-Related Smog (AP) AP...\n...     ...                                                ...\n7595      1  Around the world Ukrainian presidential candid...\n7596      2  Void is filled with Clement With the supply of...\n7597      2  Martinez leaves bitter Like Roger Clemens did ...\n7598      3  5 of arthritis patients in Singapore take Bext...\n7599      3  EBay gets into rentals EBay plans to buy the a...\n\n[7600 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Fears for T N pension after talks Unions repre...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>The Race is On: Second Private Team Sets Launc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7595</th>\n      <td>1</td>\n      <td>Around the world Ukrainian presidential candid...</td>\n    </tr>\n    <tr>\n      <th>7596</th>\n      <td>2</td>\n      <td>Void is filled with Clement With the supply of...</td>\n    </tr>\n    <tr>\n      <th>7597</th>\n      <td>2</td>\n      <td>Martinez leaves bitter Like Roger Clemens did ...</td>\n    </tr>\n    <tr>\n      <th>7598</th>\n      <td>3</td>\n      <td>5 of arthritis patients in Singapore take Bext...</td>\n    </tr>\n    <tr>\n      <th>7599</th>\n      <td>3</td>\n      <td>EBay gets into rentals EBay plans to buy the a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7600 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../datasets/test.csv')\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# – the name of tokenizer function. If None, it returns split() function, which splits the string sentence by space. If basic_english, it returns _basic_english_normalize() function, which normalize the string first and split by space.\n",
    "tokenizer = get_tokenizer(tokenizer='basic_english')\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, ser in data_iter:\n",
    "        yield tokenizer(ser['text'])  # 分词\n",
    "\n",
    "\n",
    "# Build a Vocab from an iterator.\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_df.iterrows()))\n",
    "\n",
    "vocab.insert_token(\"<unk>\", 0)\n",
    "vocab.insert_token(\"<pad>\", 1)\n",
    "vocab.set_default_index(vocab['<unk>'])  # 不在词表中的token用'<unk>'的index表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "0         [wall, st, ., bears, claw, back, into, the, bl...\n1         [carlyle, looks, toward, commercial, aerospace...\n2         [oil, and, economy, cloud, stocks, ', outlook,...\n3         [iraq, halts, oil, exports, from, main, southe...\n4         [oil, prices, soar, to, all-time, record, ,, p...\n                                ...                        \n119995    [pakistan, ', s, musharraf, says, won, ', t, q...\n119996    [renteria, signing, a, top-shelf, deal, red, s...\n119997    [saban, not, going, to, dolphins, yet, the, mi...\n119998    [today, ', s, nfl, games, pittsburgh, at, ny, ...\n119999    [nets, get, carter, from, raptors, indianapoli...\nLength: 120000, dtype: object"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_sentence = pd.Series(list(yield_tokens(train_df.iterrows())))\n",
    "train_split_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "0         29\n1         42\n2         40\n3         40\n4         43\n          ..\n119995    47\n119996    62\n119997    47\n119998    81\n119999    40\nLength: 120000, dtype: int64"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def com_sentence_len(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "train_sentence_len = train_split_sentence.apply(com_sentence_len)\n",
    "train_sentence_len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "141.0"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本长度大部分(99.9%)141以内(可以以此进行文本最大长度截断)\n",
    "np.percentile(train_sentence_len.values, q=99.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400000, 50])\n",
      "tensor([[ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
      "        [ 0.0134,  0.2368, -0.1690,  ..., -0.5666,  0.0447,  0.3039],\n",
      "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
      "        ...,\n",
      "        [-0.5118,  0.0587,  1.0913,  ..., -0.2500, -1.1250,  1.5863],\n",
      "        [-0.7590, -0.4743,  0.4737,  ...,  0.7895, -0.0141,  0.6448],\n",
      "        [ 0.0726, -0.5139,  0.4728,  ..., -0.1891, -0.5902,  0.5556]])\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练词向量文件\n",
    "vec1 = torchtext.vocab.Vectors(name=\"glove.6B.50d.txt\",\n",
    "                               cache='../../extra/glove_vector/')\n",
    "\n",
    "print(vec1.vectors.shape)\n",
    "print(vec1.vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n        ...,\n        [ 1.1296, -1.0693,  0.1338,  ...,  0.3478, -0.8490,  0.5595],\n        [-0.1712, -0.2531,  0.6790,  ...,  0.5299,  0.1299,  0.5768],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型预训练词向量矩阵\n",
    "pre_trained = vec1.get_vecs_by_tokens(vocab.get_itos())\n",
    "pre_trained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "text_pipeline = lambda line: [vocab([i])[0] for i in tokenizer(line)]\n",
    "\n",
    "\n",
    "def truncate_pad(line, text_max_len, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > text_max_len:\n",
    "        return line[:text_max_len]  # 句子截断\n",
    "    return line + [padding_token] * (text_max_len - len(line))  # 句子填充\n",
    "\n",
    "\n",
    "label_pipeline = lambda label: int(label) - 1  # 使分类标签从0开始"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\n",
      "[870, 12, 84, 138, 1482, 35, 174, 1753, 4059, 401, 21, 6558, 38435, 234, 68, 43, 17, 4478, 17, 35, 174, 19, 11302, 2448, 321, 195, 9840, 2]\n",
      "[870, 12, 84, 138, 1482, 35, 174, 1753, 4059, 401, 21, 6558, 38435, 234, 68, 43, 17, 4478, 17, 35, 174, 19, 11302, 2448, 321, 195, 9840, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def to_map_style_dataset(df):\n",
    "    r\"\"\"Convert DataFrame to map-style dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    class _MapStyleDataset(torch.utils.data.Dataset):\n",
    "\n",
    "        def __init__(self, df):\n",
    "            # TODO Avoid list issue #1296\n",
    "            self._data = df.values\n",
    "\n",
    "        def __len__(self):\n",
    "            return self._data.shape[0]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self._data[idx]\n",
    "\n",
    "    return _MapStyleDataset(df)\n",
    "\n",
    "\n",
    "test_map_data = to_map_style_dataset(test_df)\n",
    "for label, text in test_map_data:\n",
    "    print(label)\n",
    "    print(text)\n",
    "    print(text_pipeline(text))\n",
    "    print(truncate_pad(text_pipeline(text), 30, vocab['<pad>']))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "torch.Size([16, 141])\n",
      "tensor([[  870,    12,    84,  ...,     1,     1,     1],\n",
      "        [    3,   494,    22,  ...,     1,     1,     1],\n",
      "        [10971,     2,    55,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [ 2169, 27755,  7961,  ...,     1,     1,     1],\n",
      "        [88099,  7745, 14368,  ...,     1,     1,     1],\n",
      "        [ 5078,    84,     2,  ...,     1,     1,     1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list = []  # 分类标签\n",
    "    text_list = []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(truncate_pad(text_pipeline(_text), 141, vocab['<pad>']), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.stack(text_list)\n",
    "    return label_list.to(device), text_list.to(device)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(test_map_data, batch_size=16, shuffle=False, collate_fn=collate_batch)\n",
    "for i in test_dataloader:\n",
    "    print(i[0])\n",
    "    print(i[1].shape)\n",
    "    print(i[1])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-pytorch_env-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch_env] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}